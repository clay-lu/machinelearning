---
title: "DS_finalproject"
author: "Pengfei Lu"
date: "2024-05-10"
output: html_document
---
```{r}
library(dplyr)
library(TTR)
library(randomForest)
library(lubridate)
library(tree)
library(ggplot2)
library(keras)
library(skimr)
library(GGally)
library(corrplot)
library(tidyverse)
library(ROSE)
library(caret)
library(synthpop)
library(pROC)
library(e1071)
library(rpart)
library(rpart.plot)
library(xgboost)
```

```{r}
train_data = read.csv("/Users/pengfeilu/Desktop/Courses/Data Science & BI/FinalProject/Train_Loan_Home.csv")
test = read.csv("/Users/pengfeilu/Desktop/Courses/Data Science & BI/FinalProject/Test_Loan_Home.csv")
```

```{r}
summary(train_data)
summary(test)
```

```{r}
skim(train_data)
```

```{r}
sum(is.na(train_data))
sum(is.na(test))

```

```{r}
train_data <- train_data %>%
  mutate(across(c(Gender, Married, Dependents, Self_Employed, LoanAmount, Loan_Amount_Term, Credit_History),
                ~ifelse(is.na(.), median(., na.rm = TRUE), .)))
test <- test %>%
  mutate(across(where(is.numeric), ~ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
  mutate(across(where(is.character), ~ifelse(is.na(.), Mode(.), .)))

# Select only numeric columns from your training data
numeric_data <- train_data %>% 
  select_if(is.numeric)  # Select only numeric columns

# Compute the correlation matrix for numeric data
cor_matrix <- cor(numeric_data, use = "complete.obs")

# Visualize the correlation matrix
corrplot(cor_matrix, method = "color", type = "upper", order = "hclust",
         addCoef.col = "black",  # Add correlation coefficients in black color
         diag = FALSE)  # Do not show the diagonal
```
```{r}
categorical_columns <- c("Gender", "Married", "Education", "Self_Employed", "Property_Area")
train_data[categorical_columns] <- lapply(train_data[categorical_columns], factor)
test[categorical_columns] <- lapply(test[categorical_columns], factor)
```

```{r}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```

```{r}
train_data$TotalIncome <- train_data$ApplicantIncome + train_data$CoapplicantIncome
test$TotalIncome <- test$ApplicantIncome + test$CoapplicantIncome
```

```{r}
numeric_data <- select(train_data, where(is.numeric))
cor_matrix <- cor(numeric_data, use = "complete.obs")
corrplot(cor_matrix, method = "color", type = "upper", order = "hclust", addCoef.col = "black")
```

```{r}
categorical_data <- train_data %>%
  select_if(~is.factor(.) || is.character(.)) %>%
  select(-Loan_ID)  # Exclude the Loan_ID column

long_data <- categorical_data %>%
  pivot_longer(cols = everything(), names_to = "variable", values_to = "value") %>%
  group_by(variable, value) %>%
  summarise(count = n(), .groups = 'drop')

ggplot(long_data, aes(x = value, y = count)) +
  geom_bar(stat = "identity") +
  facet_wrap(~variable, scales = "free_x", nrow = 2) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5, size = 8)) +
  labs(title = "Distribution of Categorical Variables")
```

```{r}
train_data_cleaned <- train_data %>%
  select(-Loan_ID) %>%  
  mutate(across(where(is.numeric), ~ifelse(is.na(.), median(., na.rm = TRUE), .)),
         across(where(is.character), as.factor))


rf_model <- randomForest(Loan_Status ~ ., data = train_data_cleaned, ntree = 500, importance = TRUE)


print(rf_model)


importance_scores <- importance(rf_model, type = 1)
print(importance_scores)

importance_df <- data.frame(Feature = rownames(importance_scores), Importance = importance_scores[, "MeanDecreaseAccuracy"])

ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_col() +
  coord_flip() + 
  labs(title = "Feature Importance (Random Forest)", x = "Features", y = "Importance") +
  theme_minimal()
```

```{r}
pca_data <- train_data[, c("Credit_History", "ApplicantIncome", "LoanAmount")] 
pca_result <- prcomp(pca_data, scale. = TRUE)
summary(pca_result)

```

Logistic Modeling
```{r}
# Remove Loan_ID from the training dataset
train_data_model <- train_data[, !names(train_data) %in% "Loan_ID"]

# Remove Loan_ID from the testing dataset
test_model <- test[, !names(test) %in% "Loan_ID"]

# Now you can proceed with modeling using train_data_model and test_model

train_data_model$Loan_Status <- factor(train_data$Loan_Status, levels = c("N", "Y"))

# Fit the logistic regression model
model <- glm(Loan_Status ~ ., data = train_data_model, family = binomial())

predicted_probs <- predict(model, newdata = test_model, type = "response")

summary(model)
```

```{r}
calculate_metrics <- function(confusionMatrix) {
  # Extract counts from the confusion matrix
  TN <- confusionMatrix[1, 1]  # True Negatives: top-left
  FP <- confusionMatrix[1, 2]  # False Positives: top-right
  FN <- confusionMatrix[2, 1]  # False Negatives: bottom-left
  TP <- confusionMatrix[2, 2]  # True Positives: bottom-right

  # Calculate accuracy
  accuracy <- (TP + TN) / sum(confusionMatrix)

  # Calculate False Positive Rate (FPR) and False Negative Rate (FNR)
  FPR <- FP / (FP + TN)
  FNR <- FN / (FN + TP)

  # Calculate precision
  precision <- TP / (TP + FP)

  # Create a data frame to neatly display the metrics
  metrics_df <- data.frame(
    Metric = c("Accuracy", "False Positive Rate", "False Negative Rate", "Precision"),
    Value = c(accuracy, FPR, FNR, precision)
  )

  # Print the data frame as a table
  print(metrics_df, row.names = FALSE)
}

```

```{r}
# As there is no Loan$Status on my test dataset
# Assuming train_data includes all your data initially
set.seed(123)
indices <- createDataPartition(train_data$Loan_Status, p = 0.8, list = FALSE)
train_data <- train_data[indices, ]
test <- train_data[-indices, ]

# Both train_set and test_set now include the Loan_Status variable
# Simulate adding Loan_Status based on some logic or random assignment
# Here, just randomly assigning values for demonstration:
set.seed(123)
test$Loan_Status <- sample(c("Y", "N"), nrow(test), replace = TRUE, prob = c(0.7, 0.3))

# Now test_set includes a Loan_Status column
length(test$Loan_Status)


```


```{r}
test$predicted_prob <- predict(model, newdata = test, type = "response")

test$predicted_class <- ifelse(test$predicted_prob > 0.5, 1, 0)
confusionMatrix <- table(test$Loan_Status, test$predicted_class)

print(confusionMatrix)

```

```{r}
calculate_metrics(confusionMatrix)
```

```{r}
# Decision Tree Visualization
train_data_selected <- train_data %>% select(-Loan_ID) 

set.seed(123)
split <- createDataPartition(train_data_selected$Loan_Status, p = 0.75, list = FALSE)
train_tree <- train_data_selected[split, ]
test_tree <- train_data_selected[-split, ]
balanced_data <- ovun.sample(Loan_Status ~ . , data = train_tree, method = "both", N = 20000, p = 0.3)$data
decision_tree_model <- rpart(Loan_Status ~ ., data = balanced_data, method = "class")
rpart.plot(decision_tree_model, main="Decision Tree", extra=102, under=TRUE, faclen=0)

```

```{r}
importance <- as.data.frame(varImp(decision_tree_model, scale=FALSE))
print(importance)
```

```{r}
# Predicting and evaluating the model
test_tree$tree_prob_predictions <- predict(decision_tree_model, newdata = test_tree, type = "prob")
test_tree$predictions <- ifelse(test_tree$tree_prob_predictions[, "Y"] >= 0.5, "Y", "N")

# Ensure predictions are factorized with the same levels as the actual data
test_tree$predictions <- factor(test_tree$predictions, levels = c("N", "Y"))

# Assuming the test dataset now includes a 'Loan_Status' column and it is factorized
test_tree$Loan_Status <- factor(test_tree$Loan_Status, levels = c("N", "Y"))

# Now calculate the confusion matrix
conf_matrix <- confusionMatrix(test_tree$predictions, test_tree$Loan_Status)
print(conf_matrix)

```

```{r}
test_tree$tree_prob_predictions <- predict(decision_tree_model, newdata = test_tree, type = "prob")
test_tree$tree_positive_probs <- test_tree$tree_prob_predictions[, "Y"]
tree_roc_result <- roc(test_tree$Loan_Status, test_tree$tree_positive_probs)
```

```{r}
tree_auc_value <- auc(tree_roc_result)
plot(tree_roc_result, main = "ROC Curve for Decision Tree", col = "#1c61b6", lwd=3) 
text(x = 0.6, y = 0.2, labels = paste("AUC =", round(tree_auc_value, 3)), cex = 1.2, col = "blue")
```
****Random Forest model****
```{r}
# # Load libraries
# library(randomForest)
# library(ggplot2)
# library(dplyr)
# 
# # Load the data
# train_data = read.csv("/Users/pengfeilu/Desktop/Data Science & BI/FinalProject/Train_Loan_Home.csv")
# test = read.csv("/Users/pengfeilu/Desktop/Data Science & BI/FinalProject/Test_Loan_Home.csv")
# 
# # Check column names to avoid the 'ApplicantIncome' not found error
# print(names(train_data))
# print(names(test))



```

```{r}
# Check the structure of the data to ensure correct formats
str(train_data)

# If Loan_Status is not a factor, convert it
train_data$Loan_Status <- as.factor(train_data$Loan_Status)

# Check if the conversion was successful
str(train_data$Loan_Status)




```


```{r}
# Check for NA values in the dataset
sum(is.na(train_data))

# Remove rows with NA values, or use another method for handling them
train_data <- na.omit(train_data)

# Alternatively, impute NAs, especially for continuous variables
# This is a simple mean imputation example for a continuous variable:
if(any(is.na(train_data$ApplicantIncome))) {
  train_data$ApplicantIncome[is.na(train_data$ApplicantIncome)] <- mean(train_data$ApplicantIncome, na.rm = TRUE)
}


```


```{r}
# Re-train the random forest model
rf_model <- randomForest(Loan_Status ~ ., data = train_data_model)

# Check the model output
print(rf_model)


```


```{r}
# Create a variable importance plot
importance_df <- as.data.frame(importance(rf_model))
importance_df$Variable <- rownames(importance_df)

ggplot(importance_df, aes(x = reorder(Variable, MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Variable Importance in Random Forest Model", x = "Variables", y = "Importance") +
  coord_flip()  # Flips the axes for better readability

```


```{r}
# If predictions on test data are needed
test$predicted <- predict(rf_model, newdata = test)

# Summary of predictions
summary(test$predicted)

```

```{r}
# Load necessary libraries
library(randomForest)
library(pROC)
library(caret)

# Assume you've already preprocessed the data and 'train_data' is ready
# Ensure the Loan_Status is a factor with levels as "N" and "Y"
train_data$Loan_Status <- factor(train_data$Loan_Status, levels = c("N", "Y"))

# Split the data into training and test sets for modeling and validation
set.seed(123)  # for reproducibility
splitIndex <- createDataPartition(train_data$Loan_Status, p = 0.75, list = FALSE, times = 1)
train_set <- train_data[splitIndex,]
test_set <- train_data[-splitIndex,]

# Build the Random Forest model
rf_model <- randomForest(Loan_Status ~ ., data = train_set, ntree = 500, mtry = 3, importance = TRUE)

# Predict on the test set
rf_predictions <- predict(rf_model, test_set, type = "prob")

# Compute ROC curve and AUC
roc_result <- roc(test_set$Loan_Status, rf_predictions[,2])  # assuming the second column corresponds to "Y"

# Plot ROC curve
plot(roc_result, main="ROC Curve for Random Forest Model")

# Print AUC
cat("AUC:", auc(roc_result), "\n")

# Save the ROC plot if needed
ggsave("ROC_Curve_RF_Model.png", plot = last_plot(), width = 10, height = 8, dpi = 300)

# Add AUC to the plot
auc_value <- auc(roc_result)
text(0.5, 0.1, paste("AUC =", round(auc_value, 3)), col="red", cex=1.2)
```

```{r}
plot(tree_roc_result, main = "Compairson of ROC Curves", col = "red", lwd = 2)
lines(roc_result, col = "blue", lwd = 2)
legend("bottomright", legend = c("Decision Tree", "Random Forest"), col = c("red", "blue"), lwd = 2)

```
